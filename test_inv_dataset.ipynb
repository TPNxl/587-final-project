{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length: 1622\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "from dataset_classes.DEAM_CQT_shift_validation import DEAM_CQT_Shift_Validation_Set\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "annot_path = \"deam_dataset/DEAM_Annotations/annotations/annotations averaged per song/dynamic (per second annotations)/arousal.csv\"\n",
    "audio_path = \"deam_dataset/DEAM_audio/MEMD_audio/\"\n",
    "transform_path = \"transforms/\"\n",
    "transform_name = \"test_circshift\"\n",
    "train_dataset = DEAM_CQT_Shift_Validation_Set(annot_path=annot_path, audio_path=audio_path, save_files=True, transform_path=transform_path, transform_name=transform_name, train=True)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=1, shuffle=True)\n",
    "print(\"Dataset length:\", train_dataset.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  1\n",
      "1622\n",
      "12\n",
      "torch.Size([12, 60, 12])\n",
      "\n",
      "-----\n",
      "\n",
      "tensor([-0.1466, -0.1006, -0.0738, -0.0949, -0.1174, -0.1263, -0.1357, -0.1411,\n",
      "        -0.1408, -0.1473, -0.1691, -0.2920, -0.2984, -0.3051, -0.3207, -0.3254,\n",
      "        -0.3269, -0.3276, -0.3256, -0.3177, -0.3120, -0.3077, -0.3066, -0.3065,\n",
      "        -0.3075, -0.3067, -0.3099, -0.3124, -0.2994, -0.2724, -0.2757, -0.2804,\n",
      "        -0.2862, -0.2984, -0.3102, -0.3201, -0.3185, -0.3167, -0.3145, -0.3122,\n",
      "        -0.3106, -0.3060, -0.3032, -0.2991, -0.2989, -0.2984, -0.2978, -0.2972,\n",
      "        -0.2976, -0.2950, -0.2750, -0.2615, -0.2615, -0.2616, -0.2628, -0.2628,\n",
      "        -0.2591, -0.2587, -0.2615, -0.2612], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "index = 1\n",
    "print(\"Index: \", index)\n",
    "(data, target) = train_dataset.__getitem__(index)\n",
    "print(data.shape)\n",
    "print()\n",
    "print(\"-----\")\n",
    "print()\n",
    "print(target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m2v_cqt_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
