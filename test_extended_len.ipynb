{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length: 812622\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "from dataset_classes.DEAM_CQT_extended_len import DEAM_CQT_Dataset_Sliding\n",
    "import numpy as np\n",
    "import librosa\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "def cqt(y, sr, hop_length):\n",
    "    return np.abs(librosa.cqt(y=y, sr=sr, hop_length=hop_length))\n",
    "\n",
    "annot_path = \"deam_dataset/DEAM_Annotations/annotations/annotations averaged per song/dynamic (per second annotations)/arousal.csv\"\n",
    "audio_path = \"deam_dataset/DEAM_audio/MEMD_audio/\"\n",
    "transform_path = \"transforms/\"\n",
    "transform_name = \"cqt_long\"\n",
    "train_dataset = DEAM_CQT_Dataset_Sliding(annot_path=annot_path, audio_path=audio_path, save_files=True, transform_path=transform_path, transform_func=cqt, transform_name=transform_name, train=True)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=1, shuffle=True)\n",
    "test_dataset = DEAM_CQT_Dataset_Sliding(annot_path=annot_path, audio_path=audio_path, save_files=True, transform_path=transform_path, transform_func=cqt, transform_name=transform_name, train=False)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=1, shuffle=True)\n",
    "print(\"Dataset length:\", train_dataset.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, (data, target) in enumerate(train_loader):\n",
    "    continue\n",
    "for _, (data, target) in enumerate(test_loader):\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  499\n",
      "File_num: 0\n",
      "Start: 499\n",
      "End: 599\n",
      "Start annot: 26\n",
      "End annot: 31\n",
      "tensor([[1.0000, 0.1662, 0.0930, 0.2768, 0.1999, 0.0549, 0.0648, 0.1587, 0.0617,\n",
      "         0.1539, 0.1145, 0.1898],\n",
      "        [1.0000, 0.1049, 0.0782, 0.3511, 0.1244, 0.0461, 0.0499, 0.1283, 0.0467,\n",
      "         0.1154, 0.0941, 0.1527],\n",
      "        [1.0000, 0.0920, 0.1224, 0.3437, 0.1023, 0.0544, 0.0736, 0.0896, 0.0440,\n",
      "         0.0945, 0.0832, 0.1204],\n",
      "        [1.0000, 0.1235, 0.1652, 0.1796, 0.0751, 0.0735, 0.1138, 0.0950, 0.0461,\n",
      "         0.0763, 0.0602, 0.1096],\n",
      "        [1.0000, 0.1995, 0.1802, 0.1909, 0.1051, 0.1535, 0.1515, 0.1055, 0.0609,\n",
      "         0.1140, 0.0806, 0.1609],\n",
      "        [1.0000, 0.1310, 0.1080, 0.2123, 0.2413, 0.1547, 0.2082, 0.0963, 0.0464,\n",
      "         0.1089, 0.0923, 0.2112],\n",
      "        [1.0000, 0.2542, 0.1068, 0.2317, 0.1632, 0.1598, 0.2932, 0.1127, 0.0547,\n",
      "         0.1071, 0.1065, 0.2584],\n",
      "        [1.0000, 0.3799, 0.1056, 0.1866, 0.2090, 0.2542, 0.4337, 0.1166, 0.0685,\n",
      "         0.1329, 0.1369, 0.2440],\n",
      "        [1.0000, 0.4118, 0.0843, 0.1123, 0.1232, 0.2461, 0.4680, 0.1195, 0.0627,\n",
      "         0.1174, 0.0986, 0.1396],\n",
      "        [1.0000, 0.4561, 0.0933, 0.0920, 0.1272, 0.2716, 0.5200, 0.1095, 0.0744,\n",
      "         0.1173, 0.1032, 0.1661]], dtype=torch.float64)\n",
      "\n",
      "-----\n",
      "\n",
      "tensor([-0.4337, -0.4289, -0.4254, -0.4241, -0.4237], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# index = 499\n",
    "# print(\"Index: \", index)\n",
    "# (data, target) = train_dataset.__getitem__(index)\n",
    "# print(data[0:10])\n",
    "# print()\n",
    "# print(\"-----\")\n",
    "# print()\n",
    "# print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1622\n"
     ]
    }
   ],
   "source": [
    "# print(train_dataset.internal_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m2v_cqt_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
